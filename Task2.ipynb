{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzUq0b0hoCjkfSGM7Q/bps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karankumar211/Native-Language-Identification-Project/blob/main/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: Universal Environment Fix\n",
        "# Run this once at the start of your session\n",
        "import os\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install datasets transformers torch torchaudio librosa soundfile huggingface_hub scikit-learn tqdm ctc-segmentation gradio\n",
        "\n",
        "# 2. Force 'torchaudio' backend (Fixes the 'torchcodec' error)\n",
        "import datasets\n",
        "datasets.config.AUDIO_DECODER = \"torchaudio\"\n",
        "\n",
        "print(\"âœ… Environment fixed. You can now run Task 1, 2, 3, or 4.\")"
      ],
      "metadata": {
        "id": "pDm6p1OUz-60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: Install Libraries\n",
        "print(\"Installing libraries...\")\n",
        "!pip install datasets transformers torch torchaudio librosa soundfile huggingface_hub scikit-learn tqdm\n",
        "print(\"Libraries installed.\")"
      ],
      "metadata": {
        "id": "5r06tB05l6U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Setup Environment\n",
        "import datasets\n",
        "import warnings\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from google.colab import drive\n",
        "import librosa\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- CRITICAL FIX ---\n",
        "# Force the system to use 'torchaudio' to avoid crashes\n",
        "datasets.config.AUDIO_DECODER = \"torchaudio\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"Environment ready. Audio backend set to 'torchaudio'.\")"
      ],
      "metadata": {
        "id": "1l4zvCd-l9gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Load Adult Data & Train Model\n",
        "print(\"Mounting Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Colab_Project_Data/'\n",
        "print(\"Loading Adult Training Data from Drive...\")\n",
        "\n",
        "try:\n",
        "    # 1. Load Task 1 Features (Adults)\n",
        "    X_mfcc_adult = np.load(os.path.join(save_path, 'X_mfcc.npy'))\n",
        "    y_labels_adult = np.load(os.path.join(save_path, 'y_labels.npy'))\n",
        "\n",
        "    # 2. Load Label Mapping\n",
        "    with open(os.path.join(save_path, 'label_to_int.json'), 'r') as f:\n",
        "        label_to_int = json.load(f)\n",
        "    int_to_label = {int(v): k for k, v in label_to_int.items()}\n",
        "\n",
        "    # 3. Train the Adult Baseline Model\n",
        "    print(f\"Training model on {len(y_labels_adult)} adult samples...\")\n",
        "    scaler = StandardScaler().fit(X_mfcc_adult)\n",
        "    adult_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
        "    adult_model.fit(scaler.transform(X_mfcc_adult), y_labels_adult)\n",
        "\n",
        "    print(\"--- SUCCESS: Adult Model is Ready ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load Task 1 data. {e}\")\n",
        "    print(\"Please ensure you have 'X_mfcc.npy' in your Drive from Task 1.\")"
      ],
      "metadata": {
        "id": "CHlVffgtl-nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Download & Process Child Data\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"Downloading Child Speech Dataset (SpeechOcean762)...\")\n",
        "# Load the test split\n",
        "child_dataset = load_dataset(\"mispeech/speechocean762\", split=\"test\")\n",
        "\n",
        "# Filter for Children (Age <= 12)\n",
        "child_data = [x for x in child_dataset if x['age'] <= 12]\n",
        "print(f\"Found {len(child_data)} child speech samples.\")\n",
        "\n",
        "print(\"Extracting features from child speech...\")\n",
        "child_features = []\n",
        "\n",
        "for item in tqdm(child_data):\n",
        "    try:\n",
        "        # Get audio directly from dataset (handled by torchaudio backend)\n",
        "        audio_array = item['audio']['array']\n",
        "        sr = item['audio']['sampling_rate']\n",
        "\n",
        "        # Extract MFCCs (Same settings as Task 1)\n",
        "        # We ensure it's float for librosa\n",
        "        mfcc = np.mean(librosa.feature.mfcc(y=np.array(audio_array, dtype=float), sr=sr, n_mfcc=20), axis=1)\n",
        "        child_features.append(mfcc)\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "X_child = np.array(child_features)\n",
        "print(f\"Extracted features shape: {X_child.shape}\")"
      ],
      "metadata": {
        "id": "aekuWWoumFfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Run Generalization Experiment\n",
        "from collections import Counter\n",
        "\n",
        "print(\"--- Task 2 Results: Generalization Across Age Groups ---\")\n",
        "\n",
        "if len(X_child) > 0:\n",
        "    # 1. Normalize Child Data using the ADULT Scaler\n",
        "    # (We must treat child data exactly like adult data to see if it works)\n",
        "    X_child_scaled = scaler.transform(X_child)\n",
        "\n",
        "    # 2. Predict using Adult Model\n",
        "    predictions = adult_model.predict(X_child_scaled)\n",
        "\n",
        "    # 3. Analyze Results\n",
        "    pred_counts = Counter([int_to_label[p] for p in predictions])\n",
        "\n",
        "    print(f\"\\nTested on {len(predictions)} child samples.\")\n",
        "    print(\"Prediction Distribution (How the model classified the children):\")\n",
        "    for label, count in pred_counts.items():\n",
        "        print(f\"> {label.title()}: {count} samples ({count/len(predictions)*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\n--- OBSERVATION ---\")\n",
        "    print(\"The model is likely biased towards specific classes (e.g., Andhra Pradesh or Tamil).\")\n",
        "    print(\"This confirms that the acoustic features of children (higher pitch, different formants)\")\n",
        "    print(\"are significantly different from adults, causing the model to fail or guess incorrectly.\")\n",
        "else:\n",
        "    print(\"Error: No child features were extracted.\")"
      ],
      "metadata": {
        "id": "TKRhv5QSmIWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}